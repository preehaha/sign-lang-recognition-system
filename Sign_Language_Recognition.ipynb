{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72486163-c164-4896-89df-79d6e8c68a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "train_dir = \"/kaggle/input/american-sign-language-recognition/training_set\"\n",
    "eval_dir = \"/kaggle/input/american-sign-language-recognition/test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f80e616-e1e6-49b1-844f-1747978cc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to load images from given directories\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for idx, label in enumerate(uniq_labels):\n",
    "        for file in os.listdir(directory + \"/\" + label):\n",
    "            filepath = directory + \"/\" + label + \"/\" + file\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
    "            images.append(image)\n",
    "            labels.append(idx)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f88cb58-5264-452a-b5c7-cd13eca9c381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "if uniq_labels == sorted(os.listdir(eval_dir)):\n",
    "    X_eval, y_eval = load_images(directory = eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b75d933-9938-42bf-8aa5-cd788c416a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uniq_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9b9f0a-3fd5-41f7-b400-b0921f80e8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_eval = keras.utils.to_categorical(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969b24ea-a57d-44a2-aa76-270c063153ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b46c06-aa0b-4649-973d-81a2061dfe48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "X_eval = X_eval.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e37d20-d28c-47ed-9ca6-b8640d3490d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_vgg16 = VGG16(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc6b795c-d853-47e5-8393-6abd8c5c0e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 256, 256, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_resnet = ResNet50(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceda5f99-b372-47fe-9b93-9297d9de8697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#don't train existing weights for vgg16\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#don't train existing weights for resnet50\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8079e883-ebb0-4ed4-bcb0-56875b7be753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#don't train existing weights for vgg16\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#don't train existing weights for resnet50\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52938429-dc58-43eb-934c-44f095c2dc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier2 = classifier_resnet.output#head mode\n",
    "classifier2 = Flatten()(classifier2)#adding layer of flatten\n",
    "classifier2 = Dropout(0.6)(classifier2)\n",
    "classifier2 = Dense(units=40, activation='softmax')(classifier2)\n",
    "\n",
    "model2 = Model(inputs = classifier_resnet.input , outputs = classifier2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "480d5f35-3c40-49a7-b061-839ecb9532ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 119s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9608e532-6035-44bf-9f01-994f12797474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8c99d09-bc9a-4da2-952b-3d8af7485fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20024384 (76.39 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Saving the model of vgg16\n",
    "model.save('model_vgg16.h5')\n",
    "# Saving the model of resnet\n",
    "model2.save('model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93472c-2e36-4869-94d1-246c84b116a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0aa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy of vgg16')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy of vgg16')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a54822",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval, batch_size = 512,verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model2.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model2.predict(X_eval, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8229f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for only one prediction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/kaggle/input/american-sign-language-recognition/test_set/best of luck/11.png',target_size=(64,64))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = '1'\n",
    "elif result[0][1] == 1:\n",
    "    prediction = '10'\n",
    "elif result[0][2] == 1:\n",
    "    prediction = '2'\n",
    "elif result[0][3] == 1:\n",
    "    prediction = '3'\n",
    "elif result[0][4] == 1:\n",
    "    prediction = '4'\n",
    "elif result[0][5] == 1:\n",
    "    prediction = '5'\n",
    "elif result[0][6] == 1:\n",
    "    prediction = '6'\n",
    "elif result[0][7] == 1:\n",
    "    prediction = '7'\n",
    "elif result[0][8] == 1:\n",
    "    prediction = '8'\n",
    "elif result[0][9] == 1:\n",
    "    prediction = '9'\n",
    "elif result[0][10] == 1:\n",
    "    prediction = 'A'\n",
    "elif result[0][11] == 1:\n",
    "    prediction = 'B'\n",
    "elif result[0][12] == 1:\n",
    "    prediction = 'C'\n",
    "elif result[0][13] == 1:\n",
    "    prediction = 'D'\n",
    "elif result[0][14] == 1:\n",
    "    prediction = 'E'\n",
    "elif result[0][15] == 1:\n",
    "    prediction = 'F'\n",
    "elif result[0][16] == 1:\n",
    "    prediction = 'G'\n",
    "elif result[0][17] == 1:\n",
    "    prediction = 'H'\n",
    "elif result[0][18] == 1:\n",
    "    prediction = 'I'\n",
    "elif result[0][19] == 1:\n",
    "    prediction = 'J'\n",
    "elif result[0][20] == 1:\n",
    "    prediction = 'K'\n",
    "elif result[0][21] == 1:\n",
    "    prediction = 'L'\n",
    "elif result[0][22] == 1:\n",
    "    prediction = 'M'\n",
    "elif result[0][23] == 1:\n",
    "    prediction = 'N'\n",
    "elif result[0][24] == 1:\n",
    "    prediction = 'O'\n",
    "elif result[0][25] == 1:\n",
    "    prediction = 'P'\n",
    "elif result[0][26] == 1:\n",
    "    prediction = 'Q'\n",
    "elif result[0][27] == 1:\n",
    "    prediction = 'R'\n",
    "elif result[0][28] == 1:\n",
    "    prediction = 'S'\n",
    "elif result[0][29] == 1:\n",
    "    prediction = 'T'\n",
    "elif result[0][30] == 1:\n",
    "    prediction = 'U'\n",
    "elif result[0][31] == 1:\n",
    "    prediction = 'V'\n",
    "elif result[0][32] == 1:\n",
    "    prediction = 'W'\n",
    "elif result[0][33] == 1:\n",
    "    prediction = 'X'\n",
    "elif result[0][34] == 1:\n",
    "    prediction = 'Y'\n",
    "elif result[0][35] == 1:\n",
    "    prediction = 'Z'\n",
    "else:\n",
    "    prediction = '  '\n",
    "    \n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
